{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module: Pandas Assignments\n",
    "## Lesson: Pandas\n",
    "### Assignment 1: DataFrame Creation and Indexing\n",
    "\n",
    "1. Create a Pandas DataFrame with 4 columns and 6 rows filled with random integers. Set the index to be the first column.\n",
    "2. Create a Pandas DataFrame with columns 'A', 'B', 'C' and index 'X', 'Y', 'Z'. Fill the DataFrame with random integers and access the element at row 'Y' and column 'B'.\n",
    "\n",
    "### Assignment 2: DataFrame Operations\n",
    "\n",
    "1. Create a Pandas DataFrame with 3 columns and 5 rows filled with random integers. Add a new column that is the product of the first two columns.\n",
    "2. Create a Pandas DataFrame with 3 columns and 4 rows filled with random integers. Compute the row-wise and column-wise sum.\n",
    "\n",
    "### Assignment 3: Data Cleaning\n",
    "\n",
    "1. Create a Pandas DataFrame with 3 columns and 5 rows filled with random integers. Introduce some NaN values. Fill the NaN values with the mean of the respective columns.\n",
    "2. Create a Pandas DataFrame with 4 columns and 6 rows filled with random integers. Introduce some NaN values. Drop the rows with any NaN values.\n",
    "\n",
    "### Assignment 4: Data Aggregation\n",
    "\n",
    "1. Create a Pandas DataFrame with 2 columns: 'Category' and 'Value'. Fill the 'Category' column with random categories ('A', 'B', 'C') and the 'Value' column with random integers. Group the DataFrame by 'Category' and compute the sum and mean of 'Value' for each category.\n",
    "2. Create a Pandas DataFrame with 3 columns: 'Product', 'Category', and 'Sales'. Fill the DataFrame with random data. Group the DataFrame by 'Category' and compute the total sales for each category.\n",
    "\n",
    "### Assignment 5: Merging DataFrames\n",
    "\n",
    "1. Create two Pandas DataFrames with a common column. Merge the DataFrames using the common column.\n",
    "2. Create two Pandas DataFrames with different columns. Concatenate the DataFrames along the rows and along the columns.\n",
    "\n",
    "### Assignment 6: Time Series Analysis\n",
    "\n",
    "1. Create a Pandas DataFrame with a datetime index and one column filled with random integers. Resample the DataFrame to compute the monthly mean of the values.\n",
    "2. Create a Pandas DataFrame with a datetime index ranging from '2021-01-01' to '2021-12-31' and one column filled with random integers. Compute the rolling mean with a window of 7 days.\n",
    "\n",
    "### Assignment 7: MultiIndex DataFrame\n",
    "\n",
    "1. Create a Pandas DataFrame with a MultiIndex (hierarchical index). Perform some basic indexing and slicing operations on the MultiIndex DataFrame.\n",
    "2. Create a Pandas DataFrame with MultiIndex consisting of 'Category' and 'SubCategory'. Fill the DataFrame with random data and compute the sum of values for each 'Category' and 'SubCategory'.\n",
    "\n",
    "### Assignment 8: Pivot Tables\n",
    "\n",
    "1. Create a Pandas DataFrame with columns 'Date', 'Category', and 'Value'. Create a pivot table to compute the sum of 'Value' for each 'Category' by 'Date'.\n",
    "2. Create a Pandas DataFrame with columns 'Year', 'Quarter', and 'Revenue'. Create a pivot table to compute the mean 'Revenue' for each 'Quarter' by 'Year'.\n",
    "\n",
    "### Assignment 9: Applying Functions\n",
    "\n",
    "1. Create a Pandas DataFrame with 3 columns and 5 rows filled with random integers. Apply a function that doubles the values of the DataFrame.\n",
    "2. Create a Pandas DataFrame with 3 columns and 6 rows filled with random integers. Apply a lambda function to create a new column that is the sum of the existing columns.\n",
    "\n",
    "### Assignment 10: Working with Text Data\n",
    "\n",
    "1. Create a Pandas Series with 5 random text strings. Convert all the strings to uppercase.\n",
    "2. Create a Pandas Series with 5 random text strings. Extract the first three characters of each string.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee202765",
   "metadata": {},
   "source": [
    "# Module: Pandas Assignments\n",
    "## Lesson: Pandas\n",
    "### Assignment 1: DataFrame Creation and Indexing\n",
    "\n",
    "1. Create a Pandas DataFrame with 4 columns and 6 rows filled with random integers. Set the index to be the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d6d93337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "     A   B   C   D\n",
      "0  19  19   7   6\n",
      "1  17   5  14  10\n",
      "2   7  12   8   5\n",
      "3  14  14  14   8\n",
      "4  18  13  18   1\n",
      "5   6  15  13   1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data=pd.DataFrame(np.random.randint(1,21,size=(6,4)),columns=['A','B','C','D'])\n",
    "print(\"Original DataFrame \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "05b184d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "         A   B   C   D\n",
      "one     3   4  10   4\n",
      "two     9   4   2  19\n",
      "three   7   2   2  11\n",
      "four   15  17  19   4\n",
      "five    9  15  14   7\n",
      "six    12   6  16  12\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(np.random.randint(1,21,size=(6,4)),columns=['A','B','C','D'],index=['one','two','three','four','five','six'])\n",
    "print(\"Original DataFrame \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bb172084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "     A   B   C   D\n",
      "0   7   8  13  19\n",
      "1  15   4   2  20\n",
      "2   4  16  13  14\n",
      "3  12  19   1   4\n",
      "4  19  14   9   7\n",
      "5  20  12  17   9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data=pd.DataFrame(np.random.randint(1,21,size=(6,4)),columns=['A','B','C','D'])\n",
    "print(\"Original DataFrame \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "873dfd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After setting index \n",
      "      B   C   D\n",
      "A             \n",
      "7    8  13  19\n",
      "15   4   2  20\n",
      "4   16  13  14\n",
      "12  19   1   4\n",
      "19  14   9   7\n",
      "20  12  17   9\n"
     ]
    }
   ],
   "source": [
    "data.set_index('A',inplace=True)#Sets the elements of column A as index of the rows,basically reduces one column and sets the index\n",
    "print(\"After setting index \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "247929c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)#Now columns are reduced to 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b201e3d",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with columns 'A', 'B', 'C' and index 'X', 'Y', 'Z'. Fill the DataFrame with random integers and access the element at row 'Y' and column 'B'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa6e8e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "     A   B   C\n",
      "X  15  19   1\n",
      "Y  19  20   6\n",
      "Z   1  15  19\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(np.random.randint(1,21,size=(3,3)),columns=list(\"ABC\"),index=list(\"XYZ\"))\n",
    "print(\"Original DataFrame \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "063a4117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[\"Y\",\"B\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "318a1cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[\"Y\",\"B\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "272a814f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(20)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.at[\"Y\",\"B\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95224839",
   "metadata": {},
   "source": [
    "### Assignment 2: DataFrame Operations\n",
    "\n",
    "1. Create a Pandas DataFrame with 3 columns and 5 rows filled with random integers. Add a new column that is the product of the first two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f931a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "     0   1   2\n",
      "0  16   1   3\n",
      "1   7   8  19\n",
      "2   6   5   5\n",
      "3  12  16  11\n",
      "4   6   6   2\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(np.random.randint(1,21,size=(5,3)))\n",
    "print(\"Original DataFrame \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e84b6f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding new column \n",
      "     0   1   2  New column\n",
      "0  16   1   3          16\n",
      "1   7   8  19          56\n",
      "2   6   5   5          30\n",
      "3  12  16  11         192\n",
      "4   6   6   2          36\n"
     ]
    }
   ],
   "source": [
    "data[\"New column\"]=data[0]*data[1]\n",
    "print(\"After adding new column \\n\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c8fe05",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with 3 columns and 4 rows filled with random integers. Compute the row-wise and column-wise sum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2e3f9d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "     A   B   C\n",
      "0   5  19  11\n",
      "1   9   4   9\n",
      "2  19   7   2\n",
      "3  10   2   6\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(np.random.randint(1,21,size=(4,3)),columns=list(\"ABC\"))\n",
    "print(\"Original DataFrame \\n\",data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c85007b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row sum \n",
      " 0    35\n",
      "1    22\n",
      "2    28\n",
      "3    18\n",
      "dtype: int64\n",
      "Column sum \n",
      " A    43\n",
      "B    32\n",
      "C    28\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "row_sum=data.sum(axis=1)#horizontal sum\n",
    "column_sum=data.sum(axis=0)#vertical sum\n",
    "\n",
    "print(\"Row sum \\n\",row_sum)\n",
    "print(\"Column sum \\n\",column_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fda801",
   "metadata": {},
   "source": [
    "### Assignment 3: Data Cleaning\n",
    "\n",
    "1. Create a Pandas DataFrame with 3 columns and 5 rows filled with random integers. Introduce some NaN values. Fill the NaN values with the mean of the respective columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "98ff2c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "     A   B   C\n",
      "0  12   5  15\n",
      "1  13   7  12\n",
      "2   8   2   9\n",
      "3   8  14   4\n",
      "4   4  14   3\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(np.random.randint(1,21,size=(5,3)),columns=list(\"ABC\"))\n",
    "print(\"Original DataFrame \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "0cd71ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding NaN values \n",
      "       A     B     C\n",
      "0   NaN   5.0  15.0\n",
      "1  13.0   NaN  12.0\n",
      "2   8.0   2.0   NaN\n",
      "3   NaN  14.0   4.0\n",
      "4   4.0   NaN   3.0\n"
     ]
    }
   ],
   "source": [
    "data.iloc[0,0]=np.nan\n",
    "data.iloc[1,1]=np.nan\n",
    "data.iloc[2,2]=np.nan\n",
    "data.iloc[3,0]=np.nan\n",
    "data.iloc[4,1]=np.nan\n",
    "print(\"After adding NaN values \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e0c19c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filling NaN values with mean \n",
      "            A     B     C\n",
      "0   8.333333   5.0  15.0\n",
      "1  13.000000   7.0  12.0\n",
      "2   8.000000   2.0   8.5\n",
      "3   8.333333  14.0   4.0\n",
      "4   4.000000   7.0   3.0\n"
     ]
    }
   ],
   "source": [
    "data.fillna(data.mean(),inplace=True)#Fills each NaN value with the mean of that column \n",
    "print(\"After filling NaN values with mean \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fab1f6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    8.333333\n",
      "B    7.000000\n",
      "C    8.500000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15415141",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with 4 columns and 6 rows filled with random integers. Introduce some NaN values. Drop the rows with any NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c29872c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "     A   B   C   D\n",
      "0  13   9   8  19\n",
      "1  15   1  16  15\n",
      "2   1   7   1  14\n",
      "3   1   9  10   3\n",
      "4  18  18   8  17\n",
      "5  13   3  18   7\n"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame(np.random.randint(1,21,size=(6,4)),columns=list(\"ABCD\"))\n",
    "print(\"Original DataFrame \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d7187b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After adding NaN values \n",
      "       A     B     C     D\n",
      "0   NaN   9.0   8.0  19.0\n",
      "1   NaN   1.0  16.0   NaN\n",
      "2   NaN   7.0   1.0  14.0\n",
      "3   1.0   NaN  10.0   3.0\n",
      "4  18.0  18.0   NaN  17.0\n",
      "5  13.0   3.0   NaN   7.0\n"
     ]
    }
   ],
   "source": [
    "data.loc[0:2,\"A\"]=np.nan\n",
    "data.loc[3,\"B\"]=np.nan\n",
    "data.loc[4:5,\"C\"]=np.nan\n",
    "data.loc[1,\"D\"]=np.nan\n",
    "print(\"After adding NaN values \\n\",data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6dea327d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B      C      D\n",
       "0   True  False  False  False\n",
       "1   True  False  False   True\n",
       "2   True  False  False  False\n",
       "3  False   True  False  False\n",
       "4  False  False   True  False\n",
       "5  False  False   True  False"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f6d3df86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    True\n",
       "B    True\n",
       "C    True\n",
       "D    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "68c3ad69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    True\n",
       "1    True\n",
       "2    True\n",
       "3    True\n",
       "4    True\n",
       "5    True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c465443c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    3\n",
       "B    1\n",
       "C    2\n",
       "D    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7017bec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[True, True, True, True, True, True] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[125], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;66;03m#Very wrong\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAfter dropping rows with NaN values \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,data)\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[True, True, True, True, True, True] not found in axis'"
     ]
    }
   ],
   "source": [
    "data.drop(data.isnull().any(axis=1),inplace=True)#Very wrong\n",
    "print(\"After dropping rows with NaN values \\n\",data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab5db498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping rows with NaN values \n",
      " Empty DataFrame\n",
      "Columns: [A, B, C, D]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)#Drops all rows with NaN values\n",
    "print(\"After dropping rows with NaN values \\n\",data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e31d0",
   "metadata": {},
   "source": [
    "### Assignment 4: Data Aggregation\n",
    "\n",
    "1. Create a Pandas DataFrame with 2 columns: 'Category' and 'Value'. Fill the 'Category' column with random categories ('A', 'B', 'C') and the 'Value' column with random integers. Group the DataFrame by 'Category' and compute the sum and mean of 'Value' for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5eda3871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame \n",
      "   Column  Value\n",
      "0      B      2\n",
      "1      C     12\n",
      "2      C      1\n",
      "3      A      7\n",
      "4      C      8\n",
      "5      C     19\n",
      "6      C     11\n",
      "7      A     11\n",
      "8      A      3\n",
      "9      C      5\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Column':np.random.choice(['A','B','C'],size=10),\"Value\":np.random.randint(1,21,size=10)})\n",
    "print(\"Original DataFrame \\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7767a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column\n",
      "A    21\n",
      "B     2\n",
      "C    56\n",
      "Name: Value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "grouped=df.groupby('Column')['Value'].sum()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc547266",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with 3 columns: 'Product', 'Category', and 'Sales'. Fill the DataFrame with random data. Group the DataFrame by 'Category' and compute the total sales for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b465e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   Product Category  Sales\n",
      "0   Prod2        A     15\n",
      "1   Prod2        B      2\n",
      "2   Prod2        A     56\n",
      "3   Prod1        A     59\n",
      "4   Prod1        A     79\n",
      "5   Prod2        A     34\n",
      "6   Prod1        A     96\n",
      "7   Prod3        C     28\n",
      "8   Prod3        A     77\n",
      "9   Prod2        B     95\n",
      "Category\n",
      "A    416\n",
      "B     97\n",
      "C     28\n",
      "Name: Sales, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'Product': np.random.choice(['Prod1', 'Prod2', 'Prod3'], size=10), 'Category': np.random.choice(['A', 'B', 'C'], size=10), 'Sales': np.random.randint(1, 100, size=10)})\n",
    "print(\"Original DataFrame:\\n\",df)\n",
    "\n",
    "grouped=df.groupby('Category')['Sales'].sum()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717cdb5c",
   "metadata": {},
   "source": [
    "### Assignment 5: Merging DataFrames\n",
    "\n",
    "1. Create two Pandas DataFrames with a common column. Merge the DataFrames using the common column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61542eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame 1 \n",
      "   key  Value-1\n",
      "0   C        4\n",
      "1   C       12\n",
      "2   A       10\n",
      "3   B        3\n",
      "4   A        3\n",
      "5   C       10\n",
      "6   A       14\n",
      "7   B       19\n",
      "8   B       11\n",
      "9   D        6\n",
      "Original DataFrame 2 \n",
      "   key  Value-2\n",
      "0   E       29\n",
      "1   F       20\n",
      "2   F       39\n",
      "3   B       28\n",
      "4   A       39\n",
      "5   E       24\n",
      "6   F       23\n",
      "7   F       34\n",
      "8   E       35\n",
      "9   E       22\n"
     ]
    }
   ],
   "source": [
    "df_1=pd.DataFrame({'key':np.random.choice(list(\"ABCD\"),size=10),'Value-1':np.random.randint(1,21,size=10)})\n",
    "df_2=pd.DataFrame({'key':np.random.choice(list(\"ABEF\"),size=10),'Value-2':np.random.randint(20,41,size=10)})\n",
    "\n",
    "print(\"Original DataFrame 1 \\n\",df_1)\n",
    "print(\"Original DataFrame 2 \\n\",df_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6119ef2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After merging \n",
      "   key  Value-1  Value-2\n",
      "0   A       10       39\n",
      "1   B        3       28\n",
      "2   A        3       39\n",
      "3   A       14       39\n",
      "4   B       19       28\n",
      "5   B       11       28\n"
     ]
    }
   ],
   "source": [
    "merged=pd.merge(df_1,df_2,on='key',how=\"inner\")\n",
    "print(\"After merging \\n\",merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f112b5f",
   "metadata": {},
   "source": [
    "2. Create two Pandas DataFrames with different columns. Concatenate the DataFrames along the rows and along the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "793d2f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame 1 \n",
      "   key  Value-1\n",
      "0   B       18\n",
      "1   D        5\n",
      "2   B       13\n",
      "3   B        2\n",
      "4   D        6\n",
      "Original DataFrame 2 \n",
      "   key  Value-2\n",
      "0   G       32\n",
      "1   G       22\n",
      "2   H       32\n",
      "3   E       39\n",
      "4   F       40\n"
     ]
    }
   ],
   "source": [
    "df1=pd.DataFrame({'key':np.random.choice(list(\"ABCD\"),size=5),'Value-1':np.random.randint(1,21,size=5)})\n",
    "df2=pd.DataFrame({'key':np.random.choice(list(\"EFGH\"),size=5),'Value-2':np.random.randint(20,41,size=5)})\n",
    "\n",
    "print(\"Original DataFrame 1 \\n\",df1)\n",
    "print(\"Original DataFrame 2 \\n\",df2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a936859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Along the rows\n",
      "   key  Value-1  Value-2\n",
      "0   B     18.0      NaN\n",
      "1   D      5.0      NaN\n",
      "2   B     13.0      NaN\n",
      "3   B      2.0      NaN\n",
      "4   D      6.0      NaN\n",
      "0   G      NaN     32.0\n",
      "1   G      NaN     22.0\n",
      "2   H      NaN     32.0\n",
      "3   E      NaN     39.0\n",
      "4   F      NaN     40.0\n",
      "Along the columns\n",
      "   key  Value-1 key  Value-2\n",
      "0   B       18   G       32\n",
      "1   D        5   G       22\n",
      "2   B       13   H       32\n",
      "3   B        2   E       39\n",
      "4   D        6   F       40\n"
     ]
    }
   ],
   "source": [
    "print(\"Along the rows\\n\",pd.concat([df1,df2]))\n",
    "print(\"Along the columns\\n\",pd.concat([df1,df2],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99b92d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame 1 \n",
      "   key-1  Value-1\n",
      "0     A       19\n",
      "1     A       16\n",
      "2     D        5\n",
      "3     D       12\n",
      "4     C        6\n",
      "Original DataFrame 2 \n",
      "   key-2  Value-2\n",
      "0     F       28\n",
      "1     G       28\n",
      "2     F       36\n",
      "3     F       31\n",
      "4     H       30\n"
     ]
    }
   ],
   "source": [
    "df1=pd.DataFrame({'key-1':np.random.choice(list(\"ABCD\"),size=5),'Value-1':np.random.randint(1,21,size=5)})\n",
    "df2=pd.DataFrame({'key-2':np.random.choice(list(\"EFGH\"),size=5),'Value-2':np.random.randint(20,41,size=5)})\n",
    "\n",
    "print(\"Original DataFrame 1 \\n\",df1)\n",
    "print(\"Original DataFrame 2 \\n\",df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "398eb34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Along the rows\n",
      "   key-1  Value-1 key-2  Value-2\n",
      "0     A     19.0   NaN      NaN\n",
      "1     A     16.0   NaN      NaN\n",
      "2     D      5.0   NaN      NaN\n",
      "3     D     12.0   NaN      NaN\n",
      "4     C      6.0   NaN      NaN\n",
      "0   NaN      NaN     F     28.0\n",
      "1   NaN      NaN     G     28.0\n",
      "2   NaN      NaN     F     36.0\n",
      "3   NaN      NaN     F     31.0\n",
      "4   NaN      NaN     H     30.0\n",
      "Along the columns\n",
      "   key-1  Value-1 key-2  Value-2\n",
      "0     A       19     F       28\n",
      "1     A       16     G       28\n",
      "2     D        5     F       36\n",
      "3     D       12     F       31\n",
      "4     C        6     H       30\n"
     ]
    }
   ],
   "source": [
    "print(\"Along the rows\\n\",pd.concat([df1,df2]))\n",
    "print(\"Along the columns\\n\",pd.concat([df1,df2],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "337229e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (6, 1), indices imply (6, 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Just a try\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m56\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/frame.py:867\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    859\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    860\u001b[0m             arrays,\n\u001b[1;32m    861\u001b[0m             columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 867\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    876\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    877\u001b[0m         {},\n\u001b[1;32m    878\u001b[0m         index,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    881\u001b[0m         typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    882\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (6, 1), indices imply (6, 6)"
     ]
    }
   ],
   "source": [
    "# Just a try\n",
    "\n",
    "df=pd.DataFrame([1,2,3,4,56,7],columns=['A','B','C','D','E','F'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b8e221ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A\n",
      "0   1\n",
      "1   2\n",
      "2   3\n",
      "3   4\n",
      "4  56\n",
      "5   7\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame([1,2,3,4,56,7],columns=['A'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "60896a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4, 18,  5,  4],\n",
       "       [16,  5,  5, 20],\n",
       "       [11, 18,  6, 14],\n",
       "       [18,  3,  9,  8],\n",
       "       [ 8,  2,  8,  5],\n",
       "       [ 7,  7, 15,  4]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(1,21,size=(6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f38d7625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 18 13  2]\n",
      " [ 4 17 13 10]\n",
      " [15  6 19 17]\n",
      " [11 16  4  4]\n",
      " [ 8  5 10 18]\n",
      " [11  6  2 16]]\n",
      "    A   B   C   D\n",
      "0   4  18  13   2\n",
      "1   4  17  13  10\n",
      "2  15   6  19  17\n",
      "3  11  16   4   4\n",
      "4   8   5  10  18\n",
      "5  11   6   2  16\n"
     ]
    }
   ],
   "source": [
    "values=np.random.randint(1,21,size=(6,4))\n",
    "print(values)\n",
    "df=pd.DataFrame(values,columns=['A','B','C','D'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9886a9fb",
   "metadata": {},
   "source": [
    "### Assignment 6: Time Series Analysis\n",
    "\n",
    "1. Create a Pandas DataFrame with a datetime index and one column filled with random integers. Resample the DataFrame to compute the monthly mean of the values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee847a",
   "metadata": {},
   "source": [
    "The code demonstrates how to create a time series DataFrame, set the date as the index, and then resample it to compute the monthly mean of the data. Here's a detailed explanation:\n",
    "\n",
    "---\n",
    "\n",
    "### Step-by-Step Breakdown:\n",
    "\n",
    "#### 1. **Creating a Date Range**\n",
    "```python\n",
    "date_rng = pd.date_range(start='2022-01-01', end='2022-12-31', freq='D')\n",
    "```\n",
    "- `pd.date_range`: Generates a sequence of dates.\n",
    "- `start='2022-01-01'` and `end='2022-12-31'`: Define the range from January 1, 2022, to December 31, 2022.\n",
    "- `freq='D'`: Specifies daily frequency.\n",
    "\n",
    "#### 2. **Creating the DataFrame**\n",
    "```python\n",
    "df = pd.DataFrame(date_rng, columns=['date'])\n",
    "```\n",
    "- A DataFrame is created with a single column, `date`, containing the daily dates generated.\n",
    "\n",
    "#### 3. **Adding Random Data**\n",
    "```python\n",
    "df['data'] = np.random.randint(0, 100, size=(len(date_rng)))\n",
    "```\n",
    "- A new column, `data`, is added to the DataFrame.\n",
    "- `np.random.randint(0, 100, size=(len(date_rng)))`: Generates random integers between 0 and 99, with the same length as the date range.\n",
    "\n",
    "#### 4. **Setting the Date as the Index**\n",
    "```python\n",
    "df.set_index('date', inplace=True)\n",
    "```\n",
    "- `set_index`: Sets the `date` column as the index, converting the DataFrame into a time series format.\n",
    "\n",
    "#### Original DataFrame Example:\n",
    "```\n",
    "            data\n",
    "date            \n",
    "2022-01-01    45\n",
    "2022-01-02    78\n",
    "2022-01-03    12\n",
    "...\n",
    "2022-12-31    56\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **Resampling to Monthly Frequency**\n",
    "```python\n",
    "monthly_mean = df.resample('M').mean()\n",
    "```\n",
    "- `resample('M')`: Groups the data by the end of each month (`'M'` stands for month-end frequency).\n",
    "- `.mean()`: Computes the mean of the `data` values for each month.\n",
    "\n",
    "#### Resampled DataFrame (Monthly Mean):\n",
    "The resulting `monthly_mean` DataFrame contains one row for each month, with the mean of the `data` values for all days in that month.\n",
    "\n",
    "Example:\n",
    "```\n",
    "                 data\n",
    "date                 \n",
    "2022-01-31  48.354839\n",
    "2022-02-28  52.928571\n",
    "2022-03-31  50.258065\n",
    "...\n",
    "2022-12-31  49.677419\n",
    "```\n",
    "- **Index**: The last day of each month (month-end).\n",
    "- **Values**: The mean of the `data` values for that month.\n",
    "\n",
    "---\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "1. **Resampling**:\n",
    "   - Aggregates time series data at a different frequency (e.g., daily to monthly).\n",
    "   - Common aggregation functions: `.mean()`, `.sum()`, `.count()`, etc.\n",
    "\n",
    "2. **Time Series Index**:\n",
    "   - Setting the `date` column as the index allows pandas to perform time-based operations efficiently.\n",
    "\n",
    "3. **Use Case**:\n",
    "   - Useful for analyzing trends over longer periods by reducing granularity (e.g., daily data to monthly summaries).\n",
    "\n",
    "Let me know if you'd like to dive deeper into any part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79ccba51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04',\n",
      "               '2024-01-05', '2024-01-06', '2024-01-07', '2024-01-08',\n",
      "               '2024-01-09', '2024-01-10',\n",
      "               ...\n",
      "               '2024-12-22', '2024-12-23', '2024-12-24', '2024-12-25',\n",
      "               '2024-12-26', '2024-12-27', '2024-12-28', '2024-12-29',\n",
      "               '2024-12-30', '2024-12-31'],\n",
      "              dtype='datetime64[ns]', length=366, freq='D')\n"
     ]
    }
   ],
   "source": [
    "date_rng=pd.date_range(start=\"2024-01-01\",end=\"2024-12-31\")#by default frwquency is day which is all dates in the year \n",
    "print(date_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd13550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2024-01-31', '2024-02-29', '2024-03-31', '2024-04-30',\n",
      "               '2024-05-31', '2024-06-30', '2024-07-31', '2024-08-31',\n",
      "               '2024-09-30', '2024-10-31', '2024-11-30', '2024-12-31'],\n",
      "              dtype='datetime64[ns]', freq='ME')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/pxzd8tx100v3c427hktsb98w0000gn/T/ipykernel_3142/1959154823.py:1: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  date_rng=pd.date_range(start=\"2024-01-01\",end=\"2024-12-31\",freq='M')\n"
     ]
    }
   ],
   "source": [
    "date_rng=pd.date_range(start=\"2024-01-01\",end=\"2024-12-31\",freq='M')\n",
    "print(date_rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cd9250",
   "metadata": {},
   "source": [
    "freq='M' generates dates at month-end frequency. This means it creates dates corresponding to the last day of each month.\n",
    "If you specify start='2024-01-01', the first date generated will still be 2024-01-31 because it is the last day of the first month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a8f471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex(['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04',\n",
      "               '2024-01-05', '2024-01-06', '2024-01-07', '2024-01-08',\n",
      "               '2024-01-09', '2024-01-10',\n",
      "               ...\n",
      "               '2024-12-22', '2024-12-23', '2024-12-24', '2024-12-25',\n",
      "               '2024-12-26', '2024-12-27', '2024-12-28', '2024-12-29',\n",
      "               '2024-12-30', '2024-12-31'],\n",
      "              dtype='datetime64[ns]', length=366, freq='D')\n"
     ]
    }
   ],
   "source": [
    "date_rng=pd.date_range(start=\"2024-01-01\",end=\"2024-12-31\",freq=\"D\")#by default frwquency is day which is all dates in the year \n",
    "print(date_rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262cff2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date\n",
      "0   2024-01-01\n",
      "1   2024-01-02\n",
      "2   2024-01-03\n",
      "3   2024-01-04\n",
      "4   2024-01-05\n",
      "..         ...\n",
      "361 2024-12-27\n",
      "362 2024-12-28\n",
      "363 2024-12-29\n",
      "364 2024-12-30\n",
      "365 2024-12-31\n",
      "\n",
      "[366 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(date_rng,columns=['Date'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "895ea385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Data\n",
      "0   2024-01-01    46\n",
      "1   2024-01-02    47\n",
      "2   2024-01-03    47\n",
      "3   2024-01-04    58\n",
      "4   2024-01-05    18\n",
      "..         ...   ...\n",
      "361 2024-12-27    73\n",
      "362 2024-12-28    24\n",
      "363 2024-12-29     7\n",
      "364 2024-12-30    38\n",
      "365 2024-12-31    50\n",
      "\n",
      "[366 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"Data\"]=np.random.randint(1,101,size=366)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be587510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Data\n",
      "Date            \n",
      "2024-01-01    46\n",
      "2024-01-02    47\n",
      "2024-01-03    47\n",
      "2024-01-04    58\n",
      "2024-01-05    18\n",
      "...          ...\n",
      "2024-12-27    73\n",
      "2024-12-28    24\n",
      "2024-12-29     7\n",
      "2024-12-30    38\n",
      "2024-12-31    50\n",
      "\n",
      "[366 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df.set_index('Date',inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "30eaa364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndexResampler [freq=<MonthEnd>, axis=0, closed=right, label=right, convention=start, origin=start_day]\n"
     ]
    }
   ],
   "source": [
    "monthly=df.resample('ME')\n",
    "print(monthly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8806a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly=df.resample('ME')\n",
    "print(monthly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13703630",
   "metadata": {},
   "source": [
    "The `resample` method in pandas is a powerful tool for performing time-based group operations. It is commonly used in time series data to change the frequency of data points and perform aggregation or transformation operations.\n",
    "\n",
    "Heres a detailed explanation of how `resample` works, with a focus on `monthly_mean = df.resample('M').mean()`:\n",
    "\n",
    "---\n",
    "\n",
    "### **What Does `resample('M')` Do?**\n",
    "1. **Changes the Frequency**: \n",
    "   - The `resample` method groups data into new time intervals (called bins) based on the frequency specified.\n",
    "   - `freq='M'` groups the data by the **end of each month** (month-end frequency).\n",
    "   \n",
    "2. **Aggregation**:\n",
    "   - After grouping, the specified aggregation function (e.g., `.mean()`) is applied to the data within each time interval.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Components of `resample`**\n",
    "1. **Frequency (`'M'`)**:\n",
    "   - Determines how the data is grouped.\n",
    "   - `'M'`: Groups data by month-end.\n",
    "   - Common frequency strings:\n",
    "     - `'D'`: Daily.\n",
    "     - `'MS'`: Month-start.\n",
    "     - `'W'`: Weekly.\n",
    "     - `'Q'`: Quarterly.\n",
    "     - `'Y'`: Yearly.\n",
    "     - `'H'`: Hourly.\n",
    "     - `'T'`: Minutes.\n",
    "   \n",
    "2. **Downsampling**:\n",
    "   - Reducing the data frequency (e.g., from daily to monthly).\n",
    "   - `df.resample('M')`: Converts a daily time series into a monthly time series.\n",
    "\n",
    "3. **Upsampling**:\n",
    "   - Increasing the data frequency (e.g., from monthly to daily).\n",
    "   - When upsampling, you might need to fill missing values (`.ffill()`, `.bfill()`, etc.).\n",
    "\n",
    "4. **Aggregation Functions**:\n",
    "   - After resampling, you apply functions to aggregate data, such as:\n",
    "     - `.mean()`: Compute the mean.\n",
    "     - `.sum()`: Compute the sum.\n",
    "     - `.count()`: Count non-NaN values.\n",
    "     - `.max()` / `.min()`: Find max or min values.\n",
    "     - Custom aggregation functions.\n",
    "\n",
    "---\n",
    "\n",
    "### **How It Works in `monthly_mean = df.resample('M').mean()`**\n",
    "1. **Input DataFrame**:\n",
    "   ```python\n",
    "   df\n",
    "   ```\n",
    "   ```\n",
    "               data\n",
    "   date             \n",
    "   2022-01-01    10\n",
    "   2022-01-02    15\n",
    "   2022-01-03    20\n",
    "   ...\n",
    "   2022-12-31    25\n",
    "   ```\n",
    "\n",
    "2. **Step 1: Group Data by Month-End**:\n",
    "   - The data is divided into groups where each group represents one month.\n",
    "   - For example:\n",
    "     - January 2022: All rows from `2022-01-01` to `2022-01-31`.\n",
    "     - February 2022: All rows from `2022-02-01` to `2022-02-28`.\n",
    "\n",
    "3. **Step 2: Compute the Mean for Each Group**:\n",
    "   - The `.mean()` method computes the average of the `data` column for each month.\n",
    "\n",
    "4. **Output DataFrame**:\n",
    "   ```python\n",
    "   monthly_mean\n",
    "   ```\n",
    "   ```\n",
    "                  data\n",
    "   date               \n",
    "   2022-01-31  12.333\n",
    "   2022-02-28  14.500\n",
    "   2022-03-31  16.250\n",
    "   ...\n",
    "   2022-12-31  22.375\n",
    "   ```\n",
    "   - The `date` index now represents the **last day of each month**.\n",
    "   - The `data` column contains the mean values for each month's data.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Notes on `resample`**\n",
    "1. **Requires a DatetimeIndex**:\n",
    "   - The DataFrame must have a time-based index (e.g., `DatetimeIndex`).\n",
    "   - If not, convert a column to the index using `set_index()`.\n",
    "\n",
    "2. **Handles Missing Data**:\n",
    "   - Missing dates in the time series are handled automatically during resampling.\n",
    "\n",
    "3. **Custom Aggregations**:\n",
    "   - Use `.agg()` to apply multiple or custom aggregation functions:\n",
    "     ```python\n",
    "     df.resample('M').agg(['mean', 'sum'])\n",
    "     ```\n",
    "\n",
    "4. **Flexible Alignment**:\n",
    "   - Align by the start or end of time intervals using `MS` (month-start) or `M` (month-end).\n",
    "\n",
    "---\n",
    "\n",
    "### **Use Cases**\n",
    "- **Time Series Analysis**:\n",
    "  - Analyze trends, compute rolling averages, or aggregate metrics.\n",
    "- **Data Reduction**:\n",
    "  - Reduce high-frequency data (e.g., hourly) into lower-frequency summaries (e.g., daily or monthly).\n",
    "- **Forecasting**:\n",
    "  - Prepare data for forecasting models by aggregating to relevant frequencies.\n",
    "\n",
    "Let me know if you want code examples for specific resampling scenarios!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b085af06",
   "metadata": {},
   "source": [
    "Exactly! Here's a concise breakdown of what's happening in your case:\n",
    "\n",
    "1. **Resampling (`resample('M')`)**:\n",
    "   - Your original DataFrame has **366 rows** (daily data for a leap year like 2024).\n",
    "   - The `resample('M')` groups these rows into **12 categories or groups**, where each group corresponds to a **month** (e.g., all rows for January, February, etc.).\n",
    "\n",
    "2. **Aggregation Function (`mean()`)**:\n",
    "   - Once the data is grouped by month, the **aggregate function (`mean()`)** is applied to each group.\n",
    "   - This calculates the **average of the `data` column** for each month.\n",
    "\n",
    "3. **Result**:\n",
    "   - You get a new DataFrame with **12 rows**, where:\n",
    "     - The **index** is the month-end date for each month.\n",
    "     - The **value** is the mean of the `data` values for that month.\n",
    "\n",
    "### Visualizing the Process\n",
    "\n",
    "If the original data looks like this:\n",
    "```\n",
    "date        data\n",
    "2024-01-01   10\n",
    "2024-01-02   20\n",
    "2024-01-03   30\n",
    "...          ...\n",
    "2024-01-31   50\n",
    "```\n",
    "\n",
    "For January 2024, `resample('M').mean()` calculates:\n",
    "\\[\n",
    "\\text{mean} = \\frac{10 + 20 + 30 + \\dots + 50}{31}\n",
    "\\]\n",
    "\n",
    "And the output DataFrame would be:\n",
    "```\n",
    "date        data\n",
    "2024-01-31   Mean value for Jan\n",
    "2024-02-29   Mean value for Feb\n",
    "...          ...\n",
    "2024-12-31   Mean value for Dec\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "This is how `resample` simplifies time-series aggregation. Let me know if you'd like help visualizing this further!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fea5f9",
   "metadata": {},
   "source": [
    "### so basically it converts the 366 rows i have into 12 categories or groups and then applies the aggregate function on each such category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "89893a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Data\n",
      "Date                 \n",
      "2024-01-31  44.967742\n",
      "2024-02-29  55.896552\n",
      "2024-03-31  49.354839\n",
      "2024-04-30  57.700000\n",
      "2024-05-31  60.096774\n",
      "2024-06-30  55.000000\n",
      "2024-07-31  51.935484\n",
      "2024-08-31  53.258065\n",
      "2024-09-30  47.966667\n",
      "2024-10-31  37.580645\n",
      "2024-11-30  48.800000\n",
      "2024-12-31  50.354839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/pxzd8tx100v3c427hktsb98w0000gn/T/ipykernel_3142/3280946241.py:1: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  montly_mean=df.resample(\"M\").mean()\n"
     ]
    }
   ],
   "source": [
    "montly_mean=df.resample(\"M\").mean()\n",
    "print(montly_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943de01",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with a datetime index ranging from '2021-01-01' to '2021-12-31' and one column filled with random integers. Compute the rolling mean with a window of 7 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ba10d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Data\n",
      "0   2021-01-01    54\n",
      "1   2021-01-02    43\n",
      "2   2021-01-03    16\n",
      "3   2021-01-04    21\n",
      "4   2021-01-05    39\n",
      "..         ...   ...\n",
      "360 2021-12-27    70\n",
      "361 2021-12-28    37\n",
      "362 2021-12-29    13\n",
      "363 2021-12-30    48\n",
      "364 2021-12-31    20\n",
      "\n",
      "[365 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "date_rng=pd.date_range(start=\"2021-01-01\",end=\"2021-12-31\",freq=\"D\")\n",
    "df=pd.DataFrame({\"Date\":date_rng,\"Data\":np.random.randint(1,101,size=len(date_rng))})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c3a7863d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Data\n",
      "Date            \n",
      "2021-01-01    54\n",
      "2021-01-02    43\n",
      "2021-01-03    16\n",
      "2021-01-04    21\n",
      "2021-01-05    39\n",
      "...          ...\n",
      "2021-12-27    70\n",
      "2021-12-28    37\n",
      "2021-12-29    13\n",
      "2021-12-30    48\n",
      "2021-12-31    20\n",
      "\n",
      "[365 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "df.set_index('Date',inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0b1ba7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Data\n",
      "Date                 \n",
      "2021-01-01        NaN\n",
      "2021-01-02        NaN\n",
      "2021-01-03        NaN\n",
      "2021-01-04        NaN\n",
      "2021-01-05        NaN\n",
      "...               ...\n",
      "2021-12-27  69.285714\n",
      "2021-12-28  65.000000\n",
      "2021-12-29  56.714286\n",
      "2021-12-30  53.857143\n",
      "2021-12-31  42.857143\n",
      "\n",
      "[365 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "rolling_mean=df.rolling(window=7).mean()\n",
    "print(rolling_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7f1ee0",
   "metadata": {},
   "source": [
    "### Explanation of Rolling Mean and NaN Values:\n",
    "\n",
    "#### **What is a Rolling Mean?**\n",
    "A rolling mean (or moving average) is a statistical method used to smooth out short-term fluctuations and highlight longer-term trends in data. The method calculates the average of a window of values, which \"rolls\" through the data.\n",
    "\n",
    "For example, with `window=7`, the rolling mean takes the mean of 7 consecutive values, starting from the first row, then moves forward by one row to repeat the process.\n",
    "\n",
    "#### **Why are NaN Values Present in the Output?**\n",
    "When using a rolling window of size 7:\n",
    "1. The first 6 rows of the output will have `NaN` because there arent enough data points to fill the window.\n",
    "2. Once the window reaches the 7th row, the rolling mean can be calculated.\n",
    "\n",
    "#### Example:\n",
    "Given the column `A`:\n",
    "```\n",
    "0  10\n",
    "1   9\n",
    "2  17\n",
    "3   5\n",
    "4  20\n",
    "5  19\n",
    "6   6\n",
    "```\n",
    "- The first 6 rows will be `NaN`.\n",
    "- From row 6 onwards, the rolling mean will be calculated as the mean of rows [0,1,2,3,4,5,6].\n",
    "\n",
    "#### Correct Approach to Dropping NaN Rows:\n",
    "When working with rolling means, if you want to remove rows with `NaN`, you can use the `.dropna()` method:\n",
    "```python\n",
    "rolling_mean = df.rolling(window=7).mean()\n",
    "rolling_mean.dropna(inplace=True)\n",
    "print(rolling_mean)\n",
    "```\n",
    "\n",
    "If there are other issues in the dataset (like attempting to drop based on `True`/`False` indices), ensure the operation aligns with the actual structure of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460e93a",
   "metadata": {},
   "source": [
    "### Assignment 7: MultiIndex DataFrame\n",
    "\n",
    "1. Create a Pandas DataFrame with a MultiIndex (hierarchical index). Perform some basic indexing and slicing operations on the MultiIndex DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "91d019a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Value-1  Value-2  Value-3\n",
      "Category Subcategory                           \n",
      "A        one                1       12        2\n",
      "         two                6        6       13\n",
      "B        one               10       14        4\n",
      "         two               15        7       16\n"
     ]
    }
   ],
   "source": [
    "arrays=[['A','A','B','B'],['one','two','one','two']]\n",
    "index=pd.MultiIndex.from_arrays(arrays,names=['Category','Subcategory'])\n",
    "df=pd.DataFrame(np.random.randint(1,21,size=(4,3)),columns=['Value-1','Value-2','Value-3'],index=index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e4bcb257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing at Category 'A':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value-1</th>\n",
       "      <th>Value-2</th>\n",
       "      <th>Value-3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Subcategory</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Value-1  Value-2  Value-3\n",
       "Subcategory                           \n",
       "one                1       12        2\n",
       "two                6        6       13"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Indexing at Category 'A':\")\n",
    "df.loc['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "30768784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing at Category 'A' and SubCategory 'two':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Value-1     6\n",
       "Value-2     6\n",
       "Value-3    13\n",
       "Name: (A, two), dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Slicing at Category 'A' and SubCategory 'two':\")\n",
    "df.loc['A','two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "682d4e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(6)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['A','two']['Value-1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600fa0e",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with MultiIndex consisting of 'Category' and 'SubCategory'. Fill the DataFrame with random data and compute the sum of values for each 'Category' and 'SubCategory'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f303a9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Value-1  Value-2  Value-3\n",
      "Category Subcategory                           \n",
      "A        one               19       19       21\n",
      "         two               30        2       28\n",
      "B        one               21       28        6\n",
      "         two                4       15        3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "arrays=[['A','A','B','B'],['one','two','one','two']]\n",
    "index=pd.MultiIndex.from_arrays(arrays,names=['Category','Subcategory'])\n",
    "df=pd.DataFrame(np.random.randint(1,31,size=(4,3)),columns=['Value-1','Value-2','Value-3'],index=index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34b5e1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum by category is: \n",
      "            Value-1  Value-2  Value-3\n",
      "Category                           \n",
      "A              49       21       49\n",
      "B              25       43        9\n"
     ]
    }
   ],
   "source": [
    "category_sum=df.groupby('Category').sum()\n",
    "print(\"The sum by category is: \\n \",category_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2ba107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum by subcategory is: \n",
      "               Value-1  Value-2  Value-3\n",
      "Subcategory                           \n",
      "one               40       47       27\n",
      "two               34       17       31\n"
     ]
    }
   ],
   "source": [
    "subcategory_sum=df.groupby('Subcategory').sum()\n",
    "print(\"The sum by subcategory is: \\n \",subcategory_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d39c0f43",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Column not found: Subcategory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m subcategory_sum\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSubcategory\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe sum by subcategory is: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m,subcategory_sum)\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1951\u001b[0m, in \u001b[0;36mDataFrameGroupBy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(key) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1945\u001b[0m     \u001b[38;5;66;03m# if len == 1, then it becomes a SeriesGroupBy and this is actually\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     \u001b[38;5;66;03m# valid syntax, so don't raise\u001b[39;00m\n\u001b[1;32m   1947\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1948\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot subset columns with a tuple with more than one element. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a list instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1950\u001b[0m     )\n\u001b[0;32m-> 1951\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python(AI-ML)/venv/lib/python3.12/site-packages/pandas/core/base.py:244\u001b[0m, in \u001b[0;36mSelectionMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj:\n\u001b[0;32m--> 244\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn not found: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj[key]\u001b[38;5;241m.\u001b[39mndim\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gotitem(key, ndim\u001b[38;5;241m=\u001b[39mndim)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Column not found: Subcategory'"
     ]
    }
   ],
   "source": [
    "subcategory_sum=df.groupby('Category')['Subcategory'].sum()\n",
    "print(\"The sum by subcategory is: \\n \",subcategory_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df23c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Value-1  Value-2  Value-3\n",
      "Category Subcategory                           \n",
      "A        one                1        7        8\n",
      "         one                2       29       17\n",
      "         two                2        5       13\n",
      "         two               19       18       28\n",
      "B        one               12       29       11\n",
      "         two               18       20        2\n"
     ]
    }
   ],
   "source": [
    "arrays=[['A','A','A','A','B','B'],['one','one','two','two','one','two']]\n",
    "index=pd.MultiIndex.from_arrays(arrays,names=['Category','Subcategory'])\n",
    "df=pd.DataFrame(np.random.randint(1,31,size=(6,3)),columns=['Value-1','Value-2','Value-3'],index=index)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "606b19af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum by subcategory is: \n",
      "                        Value-1  Value-2  Value-3\n",
      "Category Subcategory                           \n",
      "A        one                3       36       25\n",
      "         two               21       23       41\n",
      "B        one               12       29       11\n",
      "         two               18       20        2\n"
     ]
    }
   ],
   "source": [
    "subcategory_sum=df.groupby(['Category','Subcategory']).sum()#First group by category and then by subcategory so gives the sum of subcategory with the same name in each category\n",
    "print(\"The sum by subcategory is: \\n \",subcategory_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7783d888",
   "metadata": {},
   "source": [
    "### Assignment 8: Pivot Tables\n",
    "\n",
    "1. Create a Pandas DataFrame with columns 'Date', 'Category', and 'Value'. Create a pivot table to compute the sum of 'Value' for each 'Category' by 'Date'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "424492dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Table\n",
      "         Date Category  Value\n",
      "0 2025-01-01        C     47\n",
      "1 2025-01-02        B     26\n",
      "2 2025-01-03        C     36\n",
      "3 2025-01-04        A     94\n",
      "4 2025-01-05        A     22\n"
     ]
    }
   ],
   "source": [
    "date_rng=pd.date_range(start='2025-01-01',end='2025-01-05',freq='D')\n",
    "df=pd.DataFrame({'Date':date_rng,'Category':np.random.choice(list('ABC'),size=5),'Value':np.random.randint(1,101,size=5)})\n",
    "print(\"Original Table\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856e4f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table\n",
      " Category       A     B     C\n",
      "Date                        \n",
      "2025-01-01   NaN   NaN  47.0\n",
      "2025-01-02   NaN  26.0   NaN\n",
      "2025-01-03   NaN   NaN  36.0\n",
      "2025-01-04  94.0   NaN   NaN\n",
      "2025-01-05  22.0   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "pivot_table=pd.pivot_table(values='Value', # The column whose values you want to aggregate.\n",
    "                           index='Date',  # The rows of the pivot table, based on the unique values of 'Date'.\n",
    "                           columns='Category', # The columns of the pivot table, based on the unique values of 'Category'.\n",
    "                           aggfunc='sum', # The aggregation function to apply; here, it sums the 'Value' column.\n",
    "                           data=df)\n",
    "print(\"Pivot Table\\n\",pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a0b16a",
   "metadata": {},
   "source": [
    "The `pd.pivot_table` function in Pandas is a powerful tool for reshaping data into a tabular format. Here's an explanation of the pivot table part in your code:\n",
    "\n",
    "### Code Breakdown:\n",
    "```python\n",
    "pivot_table = pd.pivot_table(\n",
    "    values='Value',         # The column whose values you want to aggregate.\n",
    "    index='Date',           # The rows of the pivot table, based on the unique values of 'Date'.\n",
    "    columns='Category',     # The columns of the pivot table, based on the unique values of 'Category'.\n",
    "    aggfunc='sum',          # The aggregation function to apply; here, it sums the 'Value' column.\n",
    "    data=df                 # The source DataFrame.\n",
    ")\n",
    "```\n",
    "\n",
    "### How It Works:\n",
    "1. **`values='Value'`:** This specifies the column whose values will be aggregated and displayed in the table. In this case, the `Value` column is selected.\n",
    "2. **`index='Date'`:** The unique values from the `Date` column form the rows of the pivot table.\n",
    "3. **`columns='Category'`:** The unique values from the `Category` column form the columns of the pivot table.\n",
    "4. **`aggfunc='sum'`:** The aggregation function is specified as `sum`, so the pivot table will sum up the values of the `Value` column for each combination of `Date` and `Category`.\n",
    "5. **`data=df`:** This specifies the source DataFrame from which the data is drawn.\n",
    "\n",
    "### Output:\n",
    "#### Original Table (Example):\n",
    "```\n",
    "        Date Category  Value\n",
    "0 2025-01-01        C     85\n",
    "1 2025-01-02        A     23\n",
    "2 2025-01-03        B     59\n",
    "3 2025-01-04        C     42\n",
    "4 2025-01-05        A     12\n",
    "```\n",
    "\n",
    "#### Pivot Table:\n",
    "```\n",
    "Category         A     B     C\n",
    "Date                         \n",
    "2025-01-01    NaN   NaN  85.0\n",
    "2025-01-02   23.0   NaN   NaN\n",
    "2025-01-03    NaN  59.0   NaN\n",
    "2025-01-04    NaN   NaN  42.0\n",
    "2025-01-05   12.0   NaN   NaN\n",
    "```\n",
    "\n",
    "### Explanation of Pivot Table Output:\n",
    "- The **rows** are unique dates from the `Date` column.\n",
    "- The **columns** are unique categories from the `Category` column.\n",
    "- The **cell values** are the sum of `Value` for each combination of `Date` and `Category`. If there is no value for a specific combination, the cell contains `NaN` (not a number).\n",
    "\n",
    "### Key Features:\n",
    "- Missing combinations (e.g., no 'B' category for `2025-01-01`) result in `NaN` by default.\n",
    "- The pivot table effectively summarizes data in a compact and easy-to-analyze format.\n",
    "\n",
    "Let me know if you'd like a deeper dive or examples with more complex configurations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "172110d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Table:\n",
      "         Date Category  Value\n",
      "0  2025-01-01        A      7\n",
      "1  2025-01-02        B     38\n",
      "2  2025-01-03        A     65\n",
      "3  2025-01-04        C     82\n",
      "4  2025-01-05        B     88\n",
      "5  2025-01-06        C     22\n",
      "6  2025-01-07        A     71\n",
      "7  2025-01-08        B     64\n",
      "8  2025-01-01        C     45\n",
      "9  2025-01-02        A     84\n",
      "10 2025-01-03        C     45\n",
      "11 2025-01-04        B      7\n",
      "12 2025-01-05        A     31\n",
      "13 2025-01-06        C    100\n",
      "14 2025-01-07        B     40\n",
      "15 2025-01-08        A     79\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data\n",
    "data = {\n",
    "    'Date': pd.date_range(start='2025-01-01', periods=8, freq='D').tolist() * 2,\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'B', 'C', 'A', 'C', 'B', 'A', 'C', 'B', 'A'],\n",
    "    'Value': np.random.randint(1, 101, size=16)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(\"Original Table:\")\n",
    "print(df)\n",
    "\n",
    "# Create a pivot table\n",
    "pivot_table = pd.pivot_table(\n",
    "    values='Value',\n",
    "    index='Date',\n",
    "    columns='Category',\n",
    "    aggfunc='sum',\n",
    "    data=df,\n",
    "    fill_value=0  # Replace NaN with 0 for better readability\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0043af85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pivot Table:\n",
      "Category     A   B    C\n",
      "Date                   \n",
      "2025-01-01   7   0   45\n",
      "2025-01-02  84  38    0\n",
      "2025-01-03  65   0   45\n",
      "2025-01-04   0   7   82\n",
      "2025-01-05  31  88    0\n",
      "2025-01-06   0   0  122\n",
      "2025-01-07  71  40    0\n",
      "2025-01-08  79  64    0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPivot Table:\")\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f18287",
   "metadata": {},
   "source": [
    "This line of code creates a list of dates that repeats twice. Here's a detailed explanation of how it works:\n",
    "\n",
    "### Code Breakdown:\n",
    "```python\n",
    "'Date': pd.date_range(start='2025-01-01', periods=8, freq='D').tolist() * 2\n",
    "```\n",
    "\n",
    "1. **`pd.date_range(start='2025-01-01', periods=8, freq='D')`:**\n",
    "   - **`start='2025-01-01'`:** Specifies the start date of the range.\n",
    "   - **`periods=8`**: Specifies the number of dates to generate (8 dates in total).\n",
    "   - **`freq='D'`**: Specifies the frequency as daily, so the dates will be consecutive days.\n",
    "   - **Output:** A Pandas `DatetimeIndex` object containing 8 consecutive dates from `2025-01-01` to `2025-01-08`.\n",
    "\n",
    "   Example Output:\n",
    "   ```\n",
    "   DatetimeIndex(['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04',\n",
    "                  '2025-01-05', '2025-01-06', '2025-01-07', '2025-01-08'],\n",
    "                 dtype='datetime64[ns]', freq='D')\n",
    "   ```\n",
    "\n",
    "2. **`.tolist()`:**\n",
    "   - Converts the `DatetimeIndex` object into a regular Python list.\n",
    "   - **Output:** A list of dates.\n",
    "\n",
    "   Example Output:\n",
    "   ```\n",
    "   ['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04',\n",
    "    '2025-01-05', '2025-01-06', '2025-01-07', '2025-01-08']\n",
    "   ```\n",
    "\n",
    "3. **`* 2`:**\n",
    "   - This duplicates the list by concatenating it with itself.\n",
    "   - **Output:** A list containing two copies of the dates.\n",
    "\n",
    "   Example Output:\n",
    "   ```\n",
    "   ['2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04',\n",
    "    '2025-01-05', '2025-01-06', '2025-01-07', '2025-01-08',\n",
    "    '2025-01-01', '2025-01-02', '2025-01-03', '2025-01-04',\n",
    "    '2025-01-05', '2025-01-06', '2025-01-07', '2025-01-08']\n",
    "   ```\n",
    "\n",
    "### Why Use This?\n",
    "The line is used to create a column of `Date` values in the DataFrame where each date repeats twice. This simulates scenarios with multiple data points (e.g., transactions, events) occurring on the same day, which is common in real-world datasets. It sets the stage for understanding how pivot tables handle repeated entries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ab7632",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with columns 'Year', 'Quarter', and 'Revenue'. Create a pivot table to compute the mean 'Revenue' for each 'Quarter' by 'Year'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a260cdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Table\n",
      "     Year Quarter  Revenue\n",
      "1   2021      Q1        7\n",
      "2   2024      Q2        3\n",
      "3   2024      Q2       10\n",
      "4   2020      Q2        7\n",
      "5   2020      Q4        6\n",
      "6   2020      Q4       17\n",
      "7   2024      Q3        7\n",
      "8   2023      Q4       12\n",
      "9   2024      Q4        8\n",
      "10  2024      Q3        8\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Year':np.random.choice([2020,2021,2022,2023,2024],size=10),'Quarter':np.random.choice(['Q1','Q2','Q3','Q4'],size=10),'Revenue':np.random.randint(1,21,size=10)},index=list(i for i in range(1,11)))\n",
    "print(\"Original Table\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7092c98d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table\n",
      " Quarter  Q1  Q2  Q3  Q4\n",
      "Year                   \n",
      "2020      0   7   0  23\n",
      "2021      7   0   0   0\n",
      "2023      0   0   0  12\n",
      "2024      0  13  15   8\n"
     ]
    }
   ],
   "source": [
    "pivot_table=pd.pivot_table(data=df,\n",
    "                           index='Year',\n",
    "                           columns='Quarter',\n",
    "                           values='Revenue',\n",
    "                           aggfunc='sum',\n",
    "                           fill_value=0\n",
    "            \n",
    "                           )\n",
    "\n",
    "print(\"Pivot Table\\n\",pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614d5f85",
   "metadata": {},
   "source": [
    "### Assignment 9: Applying Functions\n",
    "\n",
    "1. Create a Pandas DataFrame with 3 columns and 5 rows filled with random integers. Apply a function that doubles the values of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14a988e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Table\n",
      "    Value-1  Value-2  Value-3\n",
      "A       31       43       41\n",
      "B       65       19       95\n",
      "C       49       56       56\n",
      "D       88       29        8\n",
      "E       63       94       26\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(np.random.randint(1,101,size=(5,3)),index=list('ABCDE'),columns=['Value-1','Value-2','Value-3'])\n",
    "print(\"Original Table\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44b36f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubled Table\n",
      "    Value-1  Value-2  Value-3\n",
      "A       62       86       82\n",
      "B      130       38      190\n",
      "C       98      112      112\n",
      "D      176       58       16\n",
      "E      126      188       52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/pxzd8tx100v3c427hktsb98w0000gn/T/ipykernel_1485/462800108.py:1: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_doubled=df.applymap(lambda x:x*2)#applymap :Apply a function to a Dataframe elementwise.\n"
     ]
    }
   ],
   "source": [
    "df_doubled=df.applymap(lambda x:x*2)#applymap :Apply a function to a Dataframe elementwise.\n",
    "print(\"Doubled Table\\n\",df_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e0ee39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubled Table\n",
      "    Value-1  Value-2  Value-3\n",
      "A       62       86       82\n",
      "B      130       38      190\n",
      "C       98      112      112\n",
      "D      176       58       16\n",
      "E      126      188       52\n"
     ]
    }
   ],
   "source": [
    "df_doubled=df.map(lambda x:x*2)#map:Apply a function to a Dataframe elementwise.\n",
    "print(\"Doubled Table\\n\",df_doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0cad9",
   "metadata": {},
   "source": [
    "2. Create a Pandas DataFrame with 3 columns and 6 rows filled with random integers. Apply a lambda function to create a new column that is the sum of the existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24b1db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Table\n",
      "    Value-1  Value-2  Value-3\n",
      "A       26        2       65\n",
      "B       79        6       83\n",
      "C       96       61       60\n",
      "D       73       97       83\n",
      "E       73       41       84\n",
      "F       53       46       83\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(np.random.randint(1,101,size=(6,3)),index=list('ABCDEF'),columns=['Value-1','Value-2','Value-3'])\n",
    "print(\"Original Table\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15094855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Column Table\n",
      "    Value-1  Value-2  Value-3  Sum of Rows \n",
      "A       26        2       65            93\n",
      "B       79        6       83           168\n",
      "C       96       61       60           217\n",
      "D       73       97       83           253\n",
      "E       73       41       84           198\n",
      "F       53       46       83           182\n"
     ]
    }
   ],
   "source": [
    "df['Sum of Rows ']=df.apply(lambda x:x.sum(),axis=1)#apply:applies function to each row or column\n",
    "print(\"New Column Table\\n\",df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01958892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Row Table\n",
      "    Value-1  Value-2  Value-3  Sum of Rows   Sum of Columns \n",
      "A       26        2       65            93              NaN\n",
      "B       79        6       83           168              NaN\n",
      "C       96       61       60           217              NaN\n",
      "D       73       97       83           253              NaN\n",
      "E       73       41       84           198              NaN\n",
      "F       53       46       83           182              NaN\n"
     ]
    }
   ],
   "source": [
    "df['Sum of Columns ']=df.apply(lambda x:x.sum(),axis=0)\n",
    "print(\"New Row Table\\n\",df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "375cc01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value-1              int64\n",
       "Value-2              int64\n",
       "Value-3              int64\n",
       "Sum of Rows          int64\n",
       "Sum of Columns     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd09c90",
   "metadata": {},
   "source": [
    "### Assignment 10: Working with Text Data\n",
    "\n",
    "1. Create a Pandas Series with 5 random text strings. Convert all the strings to uppercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b67511f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      " 0         apple\n",
      "1        banana\n",
      "2        cherry\n",
      "3          date\n",
      "4    elderberry\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_data = pd.Series(['apple', 'banana', 'cherry', 'date', 'elderberry'])\n",
    "print(\"Original Series:\\n\",text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8617c3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Case Series:\n",
      " 0         APPLE\n",
      "1        BANANA\n",
      "2        CHERRY\n",
      "3          DATE\n",
      "4    ELDERBERRY\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "upper_data=text_data.str.upper()\n",
    "print(\"Upper Case Series:\\n\",upper_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6272961",
   "metadata": {},
   "source": [
    "Yes, you're correct in thinking that `text_data` is a Pandas DataFrame and that you can use the dot operator to call functions or access attributes. However, the `str` part in `text_data.str.upper()` is a special **accessor** in Pandas, which is used specifically for **vectorized string operations**. Let's break it down step-by-step:\n",
    "\n",
    "### **What is `str` in Pandas?**\n",
    "- The `.str` accessor in Pandas is not a standard attribute or method of DataFrames. Instead, it's a **string methods accessor** that allows you to apply string functions to each element in a Series (or column of a DataFrame), which is why you're able to call string operations like `upper()`.\n",
    "\n",
    "- **Pandas `str` Accessor:** It allows you to perform operations like:\n",
    "  - `text_data.str.upper()` to convert text to uppercase.\n",
    "  - `text_data.str.lower()` to convert text to lowercase.\n",
    "  - `text_data.str.contains('pattern')` to check if a pattern exists in the text.\n",
    "\n",
    "This works **on the individual string values** within the DataFrame, rather than operating directly on the entire DataFrame as a whole.\n",
    "\n",
    "### **How Does It Work?**\n",
    "When you use `.str`:\n",
    "- It **converts the Series** (or column) of string-like objects into an object that has methods specifically for string manipulations.\n",
    "- The methods available in `.str` work on **each element** of the Series (i.e., on the strings inside the DataFrame).\n",
    "\n",
    "### **Calling `upper()` with `.str`**\n",
    "Heres how it works in this case:\n",
    "```python\n",
    "upper_data = text_data.str.upper()\n",
    "```\n",
    "\n",
    "1. **`text_data`** is a DataFrame (or Series) containing string-like data.\n",
    "2. **`.str`** is the accessor that Pandas provides to apply string functions to the individual elements of the column/series.\n",
    "3. **`upper()`** is a string method that converts the strings to uppercase.\n",
    "\n",
    "So, `upper()` is applied **element-wise** on all string values in the column (or series) `text_data`, and it returns a new Series with those strings converted to uppercase.\n",
    "\n",
    "### **Why Not Just One Dot Operator?**\n",
    "You could think of `.str` as a way to access a **special group of functions** that are designed for string manipulation. If you didn't have `.str`, you would not be able to use string functions like `upper()`, `lower()`, `contains()`, etc., on a Pandas Series or DataFrame.\n",
    "\n",
    "### **Example**\n",
    "\n",
    "Let's say `text_data` is a DataFrame like this:\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "text_data = pd.DataFrame({\n",
    "    'Name': ['alice', 'bob', 'charlie', 'diana']\n",
    "})\n",
    "\n",
    "# Convert the 'Name' column to uppercase\n",
    "upper_data = text_data['Name'].str.upper()\n",
    "print(upper_data)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "0      ALICE\n",
    "1        BOB\n",
    "2    CHARLIE\n",
    "3      DIANA\n",
    "Name: Name, dtype: object\n",
    "```\n",
    "\n",
    "Here, `.str.upper()` is applied to the **'Name' column**, and each name is converted to uppercase.\n",
    "\n",
    "### **Summary**\n",
    "- **`.str`** is an accessor for string operations in Pandas.\n",
    "- It allows you to perform vectorized string operations on Series (or columns) of string-like objects.\n",
    "- Methods like `upper()`, `lower()`, `replace()`, etc., are available when you use the `.str` accessor. \n",
    "- Without `.str`, you cannot directly apply string methods on Series (or DataFrame) objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0098da",
   "metadata": {},
   "source": [
    "2. Create a Pandas Series with 5 random text strings. Extract the first three characters of each string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8f65150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Series:\n",
      " 0         Messi\n",
      "1       Ronaldo\n",
      "2        Neymar\n",
      "3          Pele\n",
      "4    Harry Kane\n",
      "dtype: object\n",
      "First three characters:\n",
      " 0    Mes\n",
      "1    Ron\n",
      "2    Ney\n",
      "3    Pel\n",
      "4    Har\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df=pd.Series(['Messi','Ronaldo','Neymar','Pele','Harry Kane'])\n",
    "print(\"Original Series:\\n\",df)\n",
    "\n",
    "df_three_characters=df.str[0:3]\n",
    "print(\"First three characters:\\n\",df_three_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb7df74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
